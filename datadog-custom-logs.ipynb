{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Sending Custom Logs and Metrics To Datadog"
      ],
      "metadata": {
        "id": "CjdPtPulw1Kt"
      },
      "id": "CjdPtPulw1Kt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup\n",
        "Install packages.\n",
        ">Secrets (API keys) **ARE USED** in this demo.\n",
        "\n",
        "To use this code you'll need to upload a `.env` file to the root directory for this notebook. Click on `File Browser` (folder) icon to view the directory. All files starting with a period are hidden by default. Click the eye icon to view them.\n",
        "\n",
        "View the [README](https://console.cloud.google.com/vertex-ai/colab/notebooks?project=vertexaiwebinar&supportedpurview=project&activeNb=projects%2Fvertexaiwebinar%2Flocations%2Fus-central1%2Frepositories%2Fccc4213c-e5f1-4017-a1ef-f1984b49b4dc) for information on how to obtain and use your own API keys from an `.env` file.\n",
        "\n"
      ],
      "metadata": {
        "id": "3NGjOySz4j1A"
      },
      "id": "3NGjOySz4j1A"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install yfinance\n",
        "!pip install faker"
      ],
      "metadata": {
        "id": "QeQlR6It9L4J"
      },
      "id": "QeQlR6It9L4J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Send Custom Logs to the Datadog API Endpoints"
      ],
      "metadata": {
        "id": "x6gACssFx2rq"
      },
      "id": "x6gACssFx2rq"
    },
    {
      "cell_type": "code",
      "id": "r7SVxws3ZAqxJkiWJMUGVIbB",
      "metadata": {
        "tags": [],
        "id": "r7SVxws3ZAqxJkiWJMUGVIbB"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Used to pull in API Keys/Secrets\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Log API endpoint\n",
        "url = 'https://http-intake.logs.datadoghq.com/v1/input'\n",
        "\n",
        "# Custom log entry\n",
        "log_entry = {\n",
        "    'message': 'Hello from Vertex AI',\n",
        "    'ddtags': 'env:development,version:1.0.1',\n",
        "    'hostname': 'gcp-vertex-ai',\n",
        "    'service': 'webinar',\n",
        "    'ddsource': 'python-colab-notebook'\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'DD-API-KEY': DD_API_KEY\n",
        "}\n",
        "\n",
        "# Convert log entry to JSON and print it\n",
        "json_log_entry = json.dumps(log_entry)\n",
        "print(\"Log Entry to be sent to Datadog:\")\n",
        "print(json_log_entry)\n",
        "\n",
        "response = requests.post(url, headers=headers, data=json.dumps(log_entry))\n",
        "\n",
        "# Check response from Datadog\n",
        "if response.status_code == 200:\n",
        "    print('Log sent successfully')\n",
        "else:\n",
        "    print(f'Failed to send log: {response.text}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Send \"Hello from NASA (and Vertex AI) Custom Log to Datadog\n",
        "This code calls the NASA image endpoint and then sends that data to the Datadog Logs API which can then be viewed in Datadog.\n",
        "\n",
        ">**NOTE:** Calling the custom NASA image (GCP Cloud Function) endpoint allows me to trigger my own app which can then be viewed in Datadog."
      ],
      "metadata": {
        "id": "yiCtVH7m1z61"
      },
      "id": "yiCtVH7m1z61"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Used to pull in API Keys/Secrets\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Log API endpoint\n",
        "dd_url = 'https://http-intake.logs.datadoghq.com/v1/input'\n",
        "\n",
        "# NASA Image API endpoint\n",
        "nasa_url = 'https://us-central1-datadog-community.cloudfunctions.net/get-nasa-image'\n",
        "\n",
        "# Get NASA image data (assuming it returns text)\n",
        "nasa_response = requests.get(nasa_url)\n",
        "\n",
        "# Check response from NASA API and store the text\n",
        "nasa_text = ''\n",
        "if nasa_response.status_code == 200:\n",
        "    nasa_text = nasa_response.text\n",
        "    print(\"\\nNASA Image Data (Text):\")\n",
        "    print(nasa_text)\n",
        "else:\n",
        "    print(f'Failed to retrieve NASA image data: {nasa_response.text}')\n",
        "\n",
        "# Custom log entry including NASA data\n",
        "log_entry = {\n",
        "    'message': 'Hello from NASA (and Vertex AI). Here is the latest NASA image data:',\n",
        "    'nasa_data': nasa_text,  # Include NASA data as a custom field\n",
        "    'ddtags': 'env:development,version:1.1.0',\n",
        "    'hostname': 'gcp-vertex-ai',\n",
        "    'service': 'webinar',\n",
        "    'ddsource': 'python-colab-notebook'\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'DD-API-KEY': DD_API_KEY\n",
        "}\n",
        "\n",
        "# Convert log entry to JSON and print it\n",
        "json_log_entry = json.dumps(log_entry)\n",
        "print(\"#####################\")\n",
        "print(\"Log Entry to be sent to Datadog:\")\n",
        "print(json_log_entry)\n",
        "\n",
        "# Send the log to Datadog\n",
        "dd_response = requests.post(dd_url, headers=headers, data=json_log_entry)\n",
        "\n",
        "# Check response from Datadog\n",
        "if dd_response.status_code == 200:\n",
        "    print(\"#####################\")\n",
        "    print('Log sent successfully')\n",
        "else:\n",
        "    print(f'Failed to send log: {dd_response.text}')\n"
      ],
      "metadata": {
        "id": "QvE1D30V3zF5"
      },
      "id": "QvE1D30V3zF5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Send Financial Market Custom Metrics to Datadog\n",
        "Using the `yfinance` open source library, look up historical data for multiple tickers and then save that information in json format so that it can be sent to datadog's metrics endpoint"
      ],
      "metadata": {
        "id": "hAC3hDW362hS"
      },
      "id": "hAC3hDW362hS"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import yfinance as yf\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "# Used to pull in API Keys/Secrets\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Metrics API endpoint\n",
        "dd_url = 'https://api.datadoghq.com/api/v1/series'\n",
        "\n",
        "# List of tickers you want to look up\n",
        "tickers = [\"DJIA\", \"NDX\"]\n",
        "\n",
        "# Define the time period for historical data\n",
        "period = \"1mo\"\n",
        "\n",
        "# Fetch historical data for all tickers\n",
        "historical_data = {}\n",
        "for ticker in tickers:\n",
        "    stock = yf.Ticker(ticker)\n",
        "    data = stock.history(period=period)\n",
        "    # Convert the data to a format suitable for sending as a metric\n",
        "    # Here we're just grabbing the Close prices for simplicity\n",
        "    historical_data[ticker] = data['Close'].tolist()\n",
        "\n",
        "# Prepare data in the format expected by Datadog's metrics endpoint\n",
        "datadog_metrics = {\n",
        "    \"series\": []\n",
        "}\n",
        "\n",
        "current_time = int(datetime.datetime.now().timestamp())\n",
        "\n",
        "for ticker, prices in historical_data.items():\n",
        "    for i, price in enumerate(prices):\n",
        "        datadog_metrics[\"series\"].append({\n",
        "            \"metric\": f\"stock.{ticker.lower()}.close\",\n",
        "            \"points\": [[current_time, price]],\n",
        "            \"type\": \"gauge\",\n",
        "            \"host\": \"gcp-vertex-ai\",\n",
        "            \"tags\": [f\"ticker:{ticker}\"]\n",
        "        })\n",
        "\n",
        "# Convert to JSON\n",
        "json_data = json.dumps(datadog_metrics)\n",
        "\n",
        "# Headers for the Datadog API request\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'DD-API-KEY': DD_API_KEY\n",
        "}\n",
        "\n",
        "# Send the data to Datadog's metrics endpoint\n",
        "response = requests.post(dd_url, headers=headers, data=json_data)\n",
        "\n",
        "# Check response from Datadog\n",
        "if response.status_code == 202:\n",
        "    print('Data sent successfully to Datadog')\n",
        "    print(json_data)\n",
        "else:\n",
        "    print(f'Failed to send data to Datadog: {response.text}')\n"
      ],
      "metadata": {
        "id": "IRkMF59k9V5f"
      },
      "id": "IRkMF59k9V5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Send Random Data to Datadog Metrics API\n",
        "\n",
        "Send randomized metrics to Datadog."
      ],
      "metadata": {
        "id": "3t8Y-tjiRDwC"
      },
      "id": "3t8Y-tjiRDwC"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "# Used to pull in API Keys/Secrets\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Metrics API endpoint\n",
        "dd_url = 'https://api.datadoghq.com/api/v1/series'\n",
        "\n",
        "# Prepare data in the format expected by Datadog's metrics endpoint\n",
        "datadog_metrics = {\n",
        "    \"series\": []\n",
        "}\n",
        "\n",
        "current_time = int(datetime.datetime.now().timestamp())\n",
        "\n",
        "# Define your custom metrics and their historical data\n",
        "# Randomly generate historical data for this example\n",
        "historical_data = {\n",
        "    \"vertex_metric1\": [random.uniform(10, 90) for _ in range(5)],\n",
        "    \"vertex_metric2\": [random.uniform(20, 60) for _ in range(5)],\n",
        "    \"vertex_metric3\": [random.uniform(30, 70) for _ in range(5)],\n",
        "    \"vertex_metric4\": [random.uniform(55, 90) for _ in range(5)],\n",
        "    \"vertex_metric5\": [random.uniform(35, 75) for _ in range(5)]\n",
        "}\n",
        "\n",
        "for custom, values in historical_data.items():\n",
        "    for i, value in enumerate(values):\n",
        "        # Generate random coordinates for each data point\n",
        "        random_latitude = round(random.uniform(-90, 90), 6)\n",
        "        random_longitude = round(random.uniform(-180, 180), 6)\n",
        "\n",
        "        # Generate a random value for each metric\n",
        "        random_value = round(value, 2)  # Round to 2 decimal places for readability\n",
        "        datadog_metrics[\"series\"].append({\n",
        "            \"metric\": f\"custom.{custom.lower()}.value\",\n",
        "            \"points\": [[current_time - i*60, random_value]],  # Simulate data for each minute\n",
        "            \"type\": \"interval\",\n",
        "            \"host\": \"vertex.ai\",\n",
        "            \"tags\": [f\"custom:{custom}\", f\"latitude:{random_latitude}\", f\"longitude:{random_longitude}\"]\n",
        "        })\n",
        "\n",
        "# Convert to JSON\n",
        "json_data = json.dumps(datadog_metrics)\n",
        "\n",
        "# Headers for the Datadog API request\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'DD-API-KEY': DD_API_KEY\n",
        "}\n",
        "\n",
        "# Send the data to Datadog's metrics endpoint\n",
        "response = requests.post(dd_url, headers=headers, data=json_data)\n",
        "\n",
        "# Print the response code from Datadog\n",
        "print(f\"Response Code from Datadog: {response.status_code}\")\n",
        "\n",
        "# Check response from Datadog\n",
        "if response.status_code == 202:\n",
        "    print('Data sent successfully to Datadog')\n",
        "    print(json_data)\n",
        "else:\n",
        "    print(f'Failed to send data to Datadog: {response.text}')\n"
      ],
      "metadata": {
        "id": "D6OzOHuORHR9"
      },
      "id": "D6OzOHuORHR9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Send Random Coordinates to Datadog Logs API"
      ],
      "metadata": {
        "id": "w4kut6Trpguw"
      },
      "id": "w4kut6Trpguw"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import random\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Function to generate a random log entry with latitude, longitude, and additional metrics\n",
        "def generate_log_entry():\n",
        "    random_number = random.randint(1, 5)  # Generate a random number between 1 and 10\n",
        "    log_entry = {\n",
        "        'message': 'Random Global Coordinates',\n",
        "        'ddtags': 'env:development,version:1.0.1',\n",
        "        'hostname': f'global-host-{random_number}',  # Append random number to hostname\n",
        "        'service': f'global-coordinates-{random_number}',  # Append random number to service\n",
        "        'ddsource': 'vertex-ai',\n",
        "        'latitude': round(random.uniform(-90, 90), 6),  # Random latitude\n",
        "        'longitude': round(random.uniform(-180, 180), 6),  # Random longitude\n",
        "        'value': random.randint(0, 500000),  # Random number between 0 and 500,000\n",
        "    }\n",
        "\n",
        "    # Add 5 additional metrics with random values between 0 and 100\n",
        "    for i in range(1, 6):\n",
        "        log_entry[f\"metric{i}\"] = round(random.uniform(0, 100), 2)\n",
        "\n",
        "    return log_entry\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Log API endpoint\n",
        "url = 'https://http-intake.logs.datadoghq.com/v1/input'\n",
        "\n",
        "# Generate a random log entry\n",
        "log_entry = generate_log_entry()\n",
        "\n",
        "headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'DD-API-KEY': DD_API_KEY\n",
        "}\n",
        "\n",
        "# Convert log entry to JSON\n",
        "json_log_entry = json.dumps(log_entry)\n",
        "print(\"Log Entry to be sent to Datadog:\")\n",
        "print(json_log_entry)\n",
        "\n",
        "# Send the log entry to Datadog\n",
        "response = requests.post(url, headers=headers, data=json_log_entry)\n",
        "\n",
        "# Check response from Datadog\n",
        "if response.status_code == 200:\n",
        "    print('Log sent successfully')\n",
        "else:\n",
        "    print(f'Failed to send log: {response.text}')\n"
      ],
      "metadata": {
        "id": "idWe_sa5mpn7"
      },
      "id": "idWe_sa5mpn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimenting with the Text-Bison-32K model\n",
        "\n",
        "Using the text bison model generate a box score for the Indianapolos 500 with fictional names. Include the car number, driver's full name, driver's home country, the number of laps completed (assuming not all cars will finish and receieve a DNF). Include the lap speed of each driver for each of the 200 laps."
      ],
      "metadata": {
        "id": "muJFQqDaTKb2"
      },
      "id": "muJFQqDaTKb2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fictional Race Using **Text-Bison-32k** Model\n",
        "\n",
        "AI Generated boxscore of a fictional Indianapolis 500 race. 🏎️ 🏁"
      ],
      "metadata": {
        "id": "cZlsM9mAkeCD"
      },
      "id": "cZlsM9mAkeCD"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "project_id = os.getenv(\"project_id\")\n",
        "\n",
        "# Constants\n",
        "MODEL_NAME = 'text-bison-32k'  # Replace with the actual model name you have access to\n",
        "\n",
        "# Function Definitions\n",
        "def generate_indianapolis_500_box_score(project_id, model_name):\n",
        "    \"\"\"\n",
        "    Generate a fictional box score for the Indianapolis 500 with fictional driver names. Do not use real names.\n",
        "    Parameters:\n",
        "        project_id (str): Project ID for Vertex AI.\n",
        "        model_name (str): The name of the model to use for generation.\n",
        "    \"\"\"\n",
        "    prompt = \"Generate a fictional box score for the Indianapolis 500 with fictional driver names. Do not use real names.\"\n",
        "\n",
        "    vertexai.init(project=project_id)\n",
        "    model = TextGenerationModel.from_pretrained(model_name)\n",
        "    response = model.predict(prompt, temperature=0.2, max_output_tokens=3000)\n",
        "\n",
        "    # Print the generated box score\n",
        "    print(\"Generated Indianapolis 500 Box Score:\")\n",
        "    print(response.text)\n",
        "\n",
        "# Main Script\n",
        "def main():\n",
        "    generate_indianapolis_500_box_score(project_id, MODEL_NAME)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "uRVIJQAeVEBK"
      },
      "id": "uRVIJQAeVEBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fictional Race Using **Gemini Pro** Model\n",
        "\n",
        "Like above, but stores the results in a variable - to be (possibly) used in a subsequent cell."
      ],
      "metadata": {
        "id": "S6xrU4T5lljZ"
      },
      "id": "S6xrU4T5lljZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import vertexai\n",
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Initialize Vertex AI with your project ID\n",
        "vertexai.init(project='vertexaiwebinar')  # Replace with your project ID\n",
        "\n",
        "# Prompt to send to Vertex AI\n",
        "prompt = \"Generate a fictional box score for the Indianapolis 500 with fictional driver names. Do not use real names.\"\n",
        "\n",
        "# Language to use\n",
        "language = \"en-US\"\n",
        "# Model name to use\n",
        "model_name = \"gemini-pro\"  # Replace with the actual model name you have access to\n",
        "\n",
        "def generate_and_display(model_name, full_prompt):\n",
        "    model = GenerativeModel(model_name)\n",
        "    responses = model.generate_content(\n",
        "        full_prompt,  # Using the combined prompt\n",
        "        generation_config={\n",
        "            \"max_output_tokens\": 2048,\n",
        "            \"temperature\": 0.99,\n",
        "            \"top_p\": 1\n",
        "        },\n",
        "        stream=True,\n",
        "    )\n",
        "    generated_texts = []\n",
        "    for response in responses:\n",
        "        generated_text = response.candidates[0].content.parts[0].text\n",
        "        print(generated_text)  # Display the generated text as output\n",
        "        generated_texts.append(generated_text)\n",
        "    return generated_texts\n",
        "\n",
        "# Call the generate_and_display function with the user-defined model name and the full prompt\n",
        "# and save the results to a variable\n",
        "generated_box_scores = generate_and_display(model_name, prompt)\n",
        "\n",
        "# Now, `generated_box_scores` contains the generated text and can be used in future code snippets.\n",
        "# The generated text is also printed as output.\n"
      ],
      "metadata": {
        "id": "aoAPiyyYb7ux"
      },
      "id": "aoAPiyyYb7ux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### View the Live Tail in Datadog\n",
        "\n",
        "View logs as they arrive in the Datadog [Live Tail View](https://app.datadoghq.com/logs/livetail?query=&view=spans).\n",
        "\n",
        "Send lap times to Datadog for random named drivers"
      ],
      "metadata": {
        "id": "ee2vg6qht1bU"
      },
      "id": "ee2vg6qht1bU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sending **Logs** Data for Each Lap\n"
      ],
      "metadata": {
        "id": "zFzHwYAU0wxY"
      },
      "id": "zFzHwYAU0wxY"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "from faker import Faker  # Library to generate fake data\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Log API endpoint\n",
        "url = 'https://http-intake.logs.datadoghq.com/v1/input'\n",
        "\n",
        "# Number of cars and laps\n",
        "num_cars = 10\n",
        "num_laps = 3\n",
        "\n",
        "def generate_random_lap_data(car_number, lap_number):\n",
        "    \"\"\"Generate random data for a car and lap based on the schema.\"\"\"\n",
        "    return {\n",
        "        \"ddsource\": \"Indy 500\",\n",
        "        \"ddtags\": \"env:production,version:1.0\",\n",
        "        \"hostname\": f\"car-{car_number}-indianapolis-500-results\",\n",
        "        \"message\": f\"Lap {lap_number} completed\",\n",
        "        \"service\": f\"{car_number}-race_results\",\n",
        "        \"driver\": fake.name(),\n",
        "        \"carNumber\": car_number,\n",
        "        \"lapNumber\": lap_number,\n",
        "        \"averageLapSpeed\": round(random.uniform(150, 230), 2)  # Generate random speed\n",
        "    }\n",
        "\n",
        "def send_to_datadog(payload):\n",
        "    \"\"\"Send the provided JSON payload as a custom log to Datadog.\"\"\"\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'DD-API-KEY': DD_API_KEY\n",
        "    }\n",
        "    json_payload = json.dumps(payload)\n",
        "    response = requests.post(url, headers=headers, data=json_payload)\n",
        "    if response.status_code == 200:\n",
        "        print(f'Log for Car {payload[\"carNumber\"]} on Lap {payload[\"lapNumber\"]} sent successfully to Datadog')\n",
        "    else:\n",
        "        print(f'Failed to send log to Datadog: {response.text}')\n",
        "\n",
        "# Loop through each lap, generating and sending log for each car\n",
        "for lap in range(1, num_laps + 1):\n",
        "    for car in range(1, num_cars + 1):\n",
        "        lap_log = generate_random_lap_data(car, lap)\n",
        "        send_to_datadog(lap_log)\n",
        "        time.sleep(1)  # Wait for 1 second before sending the next log\n",
        "\n",
        "print(\"All lap logs have been sent to Datadog.\")\n"
      ],
      "metadata": {
        "id": "1-dCjzVR0zyX"
      },
      "id": "1-dCjzVR0zyX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sending Metrics Data for Each Lap"
      ],
      "metadata": {
        "id": "F_8POTMQ3J9Q"
      },
      "id": "F_8POTMQ3J9Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "from faker import Faker  # Library to generate fake data\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Initialize Faker\n",
        "fake = Faker()\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "\n",
        "# Datadog Metrics API endpoint\n",
        "url = 'https://api.datadoghq.com/api/v1/series'\n",
        "\n",
        "# Number of cars and laps\n",
        "num_cars = 10\n",
        "num_laps = 3\n",
        "\n",
        "def generate_metric_data(car_number, lap_number):\n",
        "    \"\"\"Generate metric data for a car and lap.\"\"\"\n",
        "    return {\n",
        "        \"metric\": \"race.lap.speed\",\n",
        "        \"points\": [[int(time.time()), round(random.uniform(150, 230), 2)]],\n",
        "        \"type\": \"gauge\",\n",
        "        \"host\": f\"car-{car_number}-indianapolis-500-results\",\n",
        "        \"tags\": [\n",
        "            f\"env:production\",\n",
        "            f\"version:1.0\",\n",
        "            f\"driver:{fake.name()}\",\n",
        "            f\"car_number:{car_number}\",\n",
        "            f\"lap_number:{lap_number}\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "def send_to_datadog(metrics):\n",
        "    \"\"\"Send the provided metric data to Datadog.\"\"\"\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'DD-API-KEY': DD_API_KEY\n",
        "    }\n",
        "    payload = {\n",
        "        \"series\": metrics\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
        "    if response.status_code == 202:\n",
        "        print('Metric data sent successfully to Datadog')\n",
        "    else:\n",
        "        print(f'Failed to send metric data to Datadog: {response.text}')\n",
        "\n",
        "# Loop through each lap, generating and sending metric data for each car\n",
        "for lap in range(1, num_laps + 1):\n",
        "    metrics = []\n",
        "    for car in range(1, num_cars + 1):\n",
        "        metric_data = generate_metric_data(car, lap)\n",
        "        # Display the metric data on the screen\n",
        "        print(f\"Generated Metric Data for Car {car} on Lap {lap}: {json.dumps(metric_data, indent=2)}\")\n",
        "        metrics.append(metric_data)\n",
        "    send_to_datadog(metrics)\n",
        "    time.sleep(1)  # Wait for 1 second before sending the next set of metrics\n",
        "\n",
        "print(\"All metric data have been sent to Datadog.\")\n"
      ],
      "metadata": {
        "id": "O1dLlKu43PPu"
      },
      "id": "O1dLlKu43PPu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sends Metrics & Logs At the Same Time\n",
        "In order to see correlation.\n",
        ">NOTE: Open the Live Tail before running this."
      ],
      "metadata": {
        "id": "Uxd80mo3Dpms"
      },
      "id": "Uxd80mo3Dpms"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import vertexai\n",
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "DD_API_KEY = os.getenv(\"DD_API_KEY\")\n",
        "VERTEX_PROJECT_ID = os.getenv(\"VERTEX_PROJECT_ID\")  # Your Vertex AI project ID\n",
        "\n",
        "# Datadog Metrics and Logs API endpoints\n",
        "datadog_metrics_url = 'https://api.datadoghq.com/api/v1/series'\n",
        "datadog_logs_url = 'https://http-intake.logs.datadoghq.com/v1/input'\n",
        "\n",
        "# Model name to use\n",
        "MODEL_NAME = 'text-bison-32k'  # Replace with the actual model name you have access to\n",
        "\n",
        "def generate_driver_names(project_id, model_name):\n",
        "    \"\"\"Generate a list of fictional race car driver names.\"\"\"\n",
        "    prompt = \"Generate a list of 5 fictional race car driver names. The names should be a combination of a modern real driver and dragon fantasy.\"\n",
        "    vertexai.init(project=project_id)\n",
        "    model = TextGenerationModel.from_pretrained(model_name)\n",
        "    response = model.predict(prompt, temperature=0.8, max_output_tokens=3000)\n",
        "\n",
        "    names_text = response.text\n",
        "    # Use regex to remove numbers and unwanted characters, then strip whitespace\n",
        "    driver_names = [re.sub(r'[^A-Za-z ]', '', name).strip() for name in names_text.split('\\n') if name.strip()]\n",
        "    # Print the generated and cleaned driver names\n",
        "    print(\"Cleaned Driver Names:\")\n",
        "    print(json.dumps(driver_names, indent=2))\n",
        "    return driver_names  # Return the list of cleaned names\n",
        "\n",
        "def generate_metric_data(driver_name, car_number, lap_number):\n",
        "    \"\"\"Generate metric data for a car and lap.\"\"\"\n",
        "    return {\n",
        "        \"metric\": \"race.lap.speed\",\n",
        "        \"points\": [[int(time.time()), round(random.uniform(150, 230), 2)]],\n",
        "        \"type\": \"gauge\",\n",
        "        \"host\": \"dragon-rider-results\",\n",
        "        \"tags\": [\n",
        "            f\"env:production\",\n",
        "            f\"version:1.0\",\n",
        "            f\"driver:{driver_name}\",\n",
        "            f\"car_number:{car_number}\",\n",
        "            f\"lap_number:{lap_number}\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "def send_to_datadog_metrics(metrics):\n",
        "    \"\"\"Send the provided metric data to Datadog.\"\"\"\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'DD-API-KEY': DD_API_KEY\n",
        "    }\n",
        "    payload = {\n",
        "        \"series\": metrics\n",
        "    }\n",
        "    # Print the metrics being sent to Datadog\n",
        "    print(\"Sending the following metric data to Datadog:\")\n",
        "    print(json.dumps(payload, indent=2))\n",
        "    response = requests.post(datadog_metrics_url, headers=headers, data=json.dumps(payload))\n",
        "    if response.status_code == 202:\n",
        "        print('Metric data sent successfully to Datadog')\n",
        "    else:\n",
        "        print(f'Failed to send metric data to Datadog: {response.text}')\n",
        "\n",
        "def send_to_datadog_logs(log_message):\n",
        "    \"\"\"Send a custom log message to Datadog.\"\"\"\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json',\n",
        "        'DD-API-KEY': DD_API_KEY\n",
        "    }\n",
        "    response = requests.post(datadog_logs_url, headers=headers, data=json.dumps(log_message))\n",
        "    if response.status_code == 200:\n",
        "        print('Log message sent successfully to Datadog')\n",
        "    else:\n",
        "        print(f'Failed to send log message to Datadog: {response.text}')\n",
        "\n",
        "# Generate fictional driver names\n",
        "driver_names = generate_driver_names(VERTEX_PROJECT_ID, MODEL_NAME)\n",
        "\n",
        "# Number of laps (assuming 10 for this example)\n",
        "num_laps = 10\n",
        "\n",
        "# Loop through each lap, generating and sending metric data for each driver\n",
        "for lap in range(1, num_laps + 1):\n",
        "    metrics = []\n",
        "    for i, driver_name in enumerate(driver_names):\n",
        "        metric_data = generate_metric_data(driver_name, i + 1, lap)  # Car numbers are 1-indexed\n",
        "        metrics.append(metric_data)\n",
        "        # Construct a custom log message with additional information\n",
        "        log_message = {\n",
        "            \"ddsource\": \"custom_metric_log\",\n",
        "            \"ddtags\": \"env:production,version:1.0\",\n",
        "            \"hostname\": f\"car-{i + 1}-lap-{lap}-dragon-racer-results\",\n",
        "            \"message\": f\"Driver Metrics: {driver_name}, car number: {i + 1}, lap number: {lap}\",\n",
        "            \"service\": f\"{driver_name}-race_metrics\",\n",
        "            \"metric_info\": metric_data\n",
        "        }\n",
        "    send_to_datadog_logs(log_message)\n",
        "    send_to_datadog_metrics(metrics)\n",
        "    # Wait for a random time up to 3 seconds before sending the next set of metrics\n",
        "    time.sleep(random.uniform(0, 3))\n",
        "\n",
        "print(\"All metric data and logs have been sent to Datadog.\")\n"
      ],
      "metadata": {
        "id": "4vBUpVXGDwUQ"
      },
      "id": "4vBUpVXGDwUQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}