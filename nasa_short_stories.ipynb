{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UgHJ5WTvCeAl",
      "metadata": {
        "id": "UgHJ5WTvCeAl"
      },
      "source": [
        "#  Generative AI NASA Short Stories With the Gemini Pro Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FCZxXpOiR-SC",
      "metadata": {
        "id": "FCZxXpOiR-SC"
      },
      "source": [
        "## Environment Setup\n",
        "Install packages.\n",
        ">Secrets (API keys) are **NOT** used in this demo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uu8xHNjWtjxKzC41WDAghpdA",
      "metadata": {
        "id": "Uu8xHNjWtjxKzC41WDAghpdA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4TjV4bq4aIXKoGURUlYjX30W",
      "metadata": {
        "id": "4TjV4bq4aIXKoGURUlYjX30W",
        "tags": []
      },
      "source": [
        "## Imports & Variables\n",
        "Set import requirements and set `image_info_url` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "8Q-lriV2yWBZ",
      "metadata": {
        "executionInfo": {
          "elapsed": 256,
          "status": "ok",
          "timestamp": 1705531504164,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "8Q-lriV2yWBZ"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "\n",
        "# URL to fetch the image information\n",
        "image_info_url = \"https://us-central1-datadog-community.cloudfunctions.net/get-nasa-image\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LAsAj61BQlvR",
      "metadata": {
        "id": "LAsAj61BQlvR"
      },
      "source": [
        "## Fetch the NASA Image\n",
        "Call a cloud function `image_info_url` from above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n4aeiK9lQi4t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 783,
          "status": "ok",
          "timestamp": 1705531569240,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "n4aeiK9lQi4t",
        "outputId": "7d5acff1-8c25-4a65-e46e-96d3e76d5981"
      },
      "outputs": [],
      "source": [
        "# Fetch the image URL or text\n",
        "response = requests.get(image_info_url)\n",
        "if response.status_code == 200:\n",
        "    # Print the text returned from the request\n",
        "    print(response.text)  # Displaying the text\n",
        "else:\n",
        "    print(\"Failed to retrieve the image information. Sorry\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RkfcpX_Q4es2",
      "metadata": {
        "id": "RkfcpX_Q4es2"
      },
      "source": [
        "## Set the Prompt & Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "OggdWlaFuaCL",
      "metadata": {
        "executionInfo": {
          "elapsed": 158,
          "status": "ok",
          "timestamp": 1705531686661,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "OggdWlaFuaCL"
      },
      "outputs": [],
      "source": [
        "#Model name to use\n",
        "model_name = \"gemini-pro\"\n",
        "\n",
        "#Prompt to send to Vertex AI\n",
        "prompt = \"Write a children's short story based on the text provided. Include at least one fictional character as the hero. Include the original title and image URL at the beginning of the story. Do not provide words that violate Google's Responsible AI practices\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z3-vQlk1urMU",
      "metadata": {
        "id": "z3-vQlk1urMU"
      },
      "source": [
        "## Fetch Image Info and Send to Model with Prompt\n",
        "Run the following code to import dependencies and make calls to get image url and send the prompt to the model endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2dYopgXutqi",
      "metadata": {
        "id": "b2dYopgXutqi"
      },
      "outputs": [],
      "source": [
        "#Import requests\n",
        "import vertexai\n",
        "from vertexai.preview.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Function to fetch image information from the URL as plain text\n",
        "def fetch_image_info(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text  # Return the plain text response\n",
        "    else:\n",
        "        return \"Error: Could not fetch image information\"\n",
        "\n",
        "# Fetching the image information\n",
        "image_info = fetch_image_info(image_info_url)\n",
        "\n",
        "# Generate short story based on image_info\n",
        "def generate(model_name):\n",
        "    model = GenerativeModel(model_name)\n",
        "    full_prompt = prompt + \"\\n\" + image_info  # Combining the user prompt with the image information\n",
        "    responses = model.generate_content(\n",
        "        full_prompt,  # Using the combined prompt\n",
        "        generation_config={\n",
        "            \"max_output_tokens\": 2048,\n",
        "            \"temperature\": 0.98,\n",
        "            \"top_p\": 1\n",
        "        },\n",
        "        stream=True,\n",
        "    )\n",
        "    # Print the generated content\n",
        "    for response in responses:\n",
        "        print(response.candidates[0].content.parts[0].text)\n",
        "\n",
        "# Call the generate function with the user-defined model name\n",
        "generate(model_name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
